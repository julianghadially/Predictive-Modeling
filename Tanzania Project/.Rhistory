x = model.matrix(crim~., Boston[2:14])
y = crim
cv.out = cv.glmnet(x[train,], y[train], alpha = 0)
bestlamBoston = cv.out$lambda.min
Bostonridge.mod = glmnet(x[train,], y[train], alpha = 0)
Bostonridge.pred = predict(Bostonridge.mod, newx = x[test,], s = bestlamBoston)
Boston_MSE_Ridge = mean((y[test] - Bostonridge.pred)^2)
Boston_MSE_Ridge
```
```{r, echo = FALSE}
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
bestlamBoston = cv.out$lambda.min
BostonLasso.mod = glmnet(x[train,], y[train], alpha = 1)
BostonLasso.pred = predict(BostonLasso.mod, newx = x[test,], s = bestlamBoston)
Boston_MSE_Lasso = mean((y[test] - BostonLasso.pred)^2)
Boston_MSE_Lasso
```
bestlamBoston
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
x = model.matrix(crim~., Boston[2:14])
y = crim
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
bestlamBoston = cv.out$lambda.min
bestlamBoston
BostonLasso.mod = glmnet(x[train,], y[train], alpha = 1)
BostonLasso.pred = predict(BostonLasso.mod, newx = x[test,], s = bestlamBoston)
Boston_MSE_Lasso = mean((y[test] - BostonLasso.pred)^2)
Boston_MSE_Lasso
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
validationerror = rep(0,13)
for (i in 1:13) {
coefficient = coef(subsetfit, id = i)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror[i] = mean((Boston$crim[test] - pred)^2)
}
nv = which.min(validationerror)
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coef(subsetfit, nv)
#coefficients are the same so we use the validation error for 12 variable model
validationerror[nv]
validationerror[nv]
nv
coef(subsetfit, nv)
colnames(Boston)
set.seed(6)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
x = model.matrix(crim~., Boston[2:14])
y = crim
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
subsetfit$sserr
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror = mean((Boston$crim[test] - pred)^2)
validationerror
set.seed(6)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
x = model.matrix(crim~., Boston[2:14])
y = crim
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror = mean((Boston$crim[test] - pred)^2)
validationerror
pred
validationerror = mean((Boston$crim[test] - pred[,1])^2)
validationerror
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
set.seed(6)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
x = model.matrix(crim~., Boston[2:14])
y = crim
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
?regsubsets
train.cv = sample(1:nrow(Boston[train,]), nrow(Boston[train,])*.7)
test.cv = -train.cv
#Subset selection
subsetfit = regsubsets(crim~., data = Boston[train.cv,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test.cv,])
validationerror = rep(0,13)
for (i in 1:13) {
coefficient = coef(subsetfit, id = i)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror[i] = mean((Boston$crim[test.cv] - pred)^2)
}
nv = which.min(validationerror)
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coef(subsetfit, nv)
#coefficients are the same so we use the validation error for 12 variable model
validationerror[nv]
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
validationerror = rep(0,13)
for (i in 1:13) {
coefficient = coef(subsetfit, id = i)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror[i] = mean((Boston$crim[test] - pred)^2)
}
nv = which.min(validationerror)
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coef(subsetfit, nv)
#coefficients are the same so we use the validation error for 12 variable model
validationerror[nv]
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
validationerror = rep(0,13)
for (i in 1:13) {
coefficient = coef(subsetfit, id = i)
pred = test.matrix[,names(coefficient)]%*%coefficient
validationerror[i] = mean((Boston$crim[test] - pred)^2)
}
nv = which.min(validationerror)
subsetfit = regsubsets(crim~., data = Boston, nvmax = 13)
coef(subsetfit, nv)
#coefficients are the same so we use the validation error for 12 variable model
validationerror[nv]
validationerror
set.seed(6)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
x = model.matrix(crim~., Boston[2:14])
y = crim
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
#subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
#subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
set.seed(12)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
#subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
set.seed(34)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
#subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
set.seed(12)
train = sample(1:nrow(Boston), nrow(Boston)*.7)
test = -train
subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 14)
#reg.summary = summary(subsetfit)
test.matrix = model.matrix(crim~., data = Boston[test,])
#subsetfit = regsubsets(crim~., data = Boston[train,], nvmax = 13)
coefficient = coef(subsetfit, id = 12)
pred = test.matrix[,names(coefficient)]%*%coefficient
OOS_MSE = mean((Boston$crim[test] - pred[,1])^2)
OOS_MSE
attatch(Boston)
for (i in (1:14)) {
print (i)
print(cor(Boston[,i], crim))
}
hist(crim,breaks = c(0:100), ylim = range(c(0:50)))
range(crim)
median(crim)
hist(tax)
median(tax)
summary(tax)
hist(crim,breaks = c(0:100), ylim = range(c(0:50)))
range(crim)
median(crim)
hist(crim,breaks = c(0:100), ylim = range(c(0:50)), main = 'Histogram of Crime')
pairs(Boston)
pairs(Boston[,c(1,2,13,14)])
?pairs
pairs(Boston)
colnames(Boston)
pairs(Boston[,c(1,2,6,12,13,14)])
?Boston
Boston$chas
sum(Boston$chas)
summary(Boston$ptratio)
summary(Boston$medv)
colnames(Boston)
summary(Boston$medv)
min.medv.idx = which(Boston$medv < 5.01)
min.medv.idx
min.medv.idx = which(Boston$medv < 5.00001)
min.medv.idx
min.medv.idx = which(Boston$medv == 5.0000)
min.medv.idx
Boston$medv
Boston[min.med.idx,]
Boston[min.medv.idx,]
library(mosaic)
?bwplot
summary(Boston)
Boston[min.medv.idx,]
sum(which(Boston$rm > 7))
sum(Boston$rm > 7))
sum(length(which(Boston$rm > 7)))
which(Boston$rm>7)
length(which(Boston$rm > 7))
length(which(Boston$rm > 8))
set.seed(1)
train = sample(1:length(Caravan[,1]), 1000)
test = -train
Caravantrain = Caravan[train,]
Caravantest = Caravan[test,]
library(ISLR)
attach(Caravan)
set.seed(1)
train = sample(1:length(Caravan[,1]), 1000)
test = -train
Caravantrain = Caravan[train,]
Caravantest = Caravan[test,]
Caravantest[,c(86)] <- sapply(Caravantest[,c(86)],as.character)
for (i in 1:length(Caravantest$Purchase)) {
if (Caravantest[i,]$Purchase == 'Yes') {
Caravantest[i,86] = 1
} else if (Caravantest[i,]$Purchase == 'No') {
Caravantest[i,86] = 0
}
}
#Caravantest[,c(86)] <- sapply(Caravantest[,c(86)],as.factor)
Caravantrain[,c(86)] <- sapply(Caravantrain[,c(86)],as.character)
for (i in 1:length(Caravantrain$Purchase)) {
if (Caravantrain[i,]$Purchase == 'Yes') {
Caravantrain[i,86] = as.character(1)
} else if (Caravantrain[i,]$Purchase == 'No') {
Caravantrain[i,86] = as.character(0)
}
}
set.seed(12321)
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
perc_Correct = (purchase.contingency[2,2]/(1 - purchase.contingency[2,]))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
library(kknn)
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
perc_Correct = (purchase.contingency[2,2]/(1 - purchase.contingency[2,]))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
perc_Correct = (purchase.contingency[2,2]/(1 - purchase.contingency[2,2]))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,5,7,10,15,20,30,35,40,45), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
log(10)
log(999)
log(9)
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
perc_Correct = log(purchase.contingency[2,2]/(1 - purchase.contingency[2,2]))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,5,7,10,15,20,30,35,40,45), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
odds_ratio = purchase.contingency[2,2]/(1 - purchase.contingency[2,2])
perc_Correct = log(odds_ratio/(1-odds_ratio))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,5,7,10,15,20,30,35,40,45), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
out_perc.correct = NULL
for (i in c(2,5,7,10,15,20,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
p = purchase.contingency[2,2]/sum(purchase.contingency[2,])
perc_Correct = log(p/(1-p))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,5,7,10,15,20,30,35,40,45), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
out_perc.correct = NULL
for (i in c(2,3,4,5,6,7,8,9,10,30,35,40,45)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
p = purchase.contingency[2,2]/sum(purchase.contingency[2,])
perc_Correct = log(p/(1-p))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,3,4,5,6,7,8,9,10,30,35,40,45), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
out_perc.correct = NULL
for (i in c(2,3,4,5,6,7,8,9,10)) {
kknn.mod = kknn(as.factor(Purchase)~., Caravantrain, Caravantest, k = i, kernel = 'rectangular')
yes.purchase.idx = which(kknn.mod$prob[,2] >= .20)
no.purchase.idx = which(kknn.mod$prob[,1]>.8)
kknn.mod.yes = kknn.mod$prob[,2]
kknn.mod.yes[yes.purchase.idx] = 1
kknn.mod.yes[no.purchase.idx] = 0
purchase.contingency = xtabs(~kknn.mod.yes + as.integer(Caravantest[,86]))
p = purchase.contingency[2,2]/sum(purchase.contingency[2,])
perc_Correct = log(p/(1-p))
#temp = mean((as.integer(Caravantest[,86]) - kknn.mod$fitted)^2)
out_perc.correct = c(out_perc.correct, perc_Correct)
}
bestk = which.min(out_perc.correct)
out_perc.correct.df = data.frame('k' = c(2,3,4,5,6,7,8,9,10), 'Out of Sample Perc Correct' = out_perc.correct)
plot(out_perc.correct.df, type = 'l', main = 'Choosing K with Validation: No best K')
c(1:5)
1:5
sample(0:1, 1)
sample(c(0,1), 1)
sample(c(0,1), 1)
?matrix
matrix(0,4,4)
a = matrix(0,4,4)
for (i in 1:4) {
for (j in 1:4) {
if (j > i) {
a[i,j] = i//j
else{
a[i,j] = j//i
}
}
}
}
a[1,1]
a[1,1] = 2
a
a = matrix(0,4,4)
for (i in 1:4) {
for (j in 1:4) {
if (j > i) {
a[i,j] = i/j
else{
a[i,j] = j/i
}
}
}
}
a = matrix(0,4,4)
for (i in 1:4) {
for (j in 1:4) {
if (j > i) {
a[i,j] = i/j
}
else{
a[i,j] = j/i
}
}
}
a
a = matrix(0,4,4)
for (i in 1:20) {
for (j in 1:4) {
if (j > i) {
a[i,j] = i/j
}
else{
a[i,j] = j/i
}
}
}
a = matrix(0,4,4)
for (i in 1:4) {
for (j in 1:4) {
if (j > i) {
a[i,j] = i/j
}
else{
a[i,j] = j/i
}
}
}
runApp()
library(shiny)
setwd("WorldPhones Shiny")
runApp()
for (c in c(0,1)){
print(c)
}
101000/1307
101000/1075
101000/1307-63.64
(101000/1307-63.64)/63.64
.214271**(1/5)
1.214271**(1/5)
-1
x = 63.64
for (i in 1:5) {
x = x**1.03959
print(x)
}
x = 63.64
for (i in 1:5) {
x = x*1.03959
print(x)
}
x = 63.64
for (i in 1:6) {
x = x*1.03959
print(x)
}
63.64/4.56
1/13.956
93.95*.07165
